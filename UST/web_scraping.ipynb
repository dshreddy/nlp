{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMKu3BoRRrDzAwKWTtRDslC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-L5zeeTFvODi"},"outputs":[],"source":["import os\n","import time\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# Define the path to the Downloads folder\n","downloads_folder = os.path.expanduser(\"~/Downloads\")\n","\n","urls = [\"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Normans.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Computational_complexity_theory.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Southern_California.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Sky_(United_Kingdom).html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Victoria_(Australia).html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Huguenot.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Steam_engine.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Oxygen.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/1973_oil_crisis.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/European_Union_law.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Amazon_rainforest.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Ctenophora.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Fresno,_California.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Packet_switching.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Black_Death.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Geology.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Pharmacy.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Civil_disobedience.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Construction.html\",\n","        \"https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/Private_school.html\",\n","        ]\n","\n","for i, url in enumerate(urls):\n","    time.sleep(3)\n","\n","    response = requests.get(url) # Send a GET request to the URL\n","\n","    soup = BeautifulSoup(response.text, \"html.parser\") # Create BeautifulSoup object from the response text\n","\n","    info_body_element = soup.find(class_=\"infoBody\") # Find the element with class \"infoBody\"\n","\n","    title_element = info_body_element.find(\"h1\", id=\"title\") # Find the <h1> tag within \"infoBody\" and get the text content\n","    title = title_element.get_text().strip()\n","\n","    col_md_6_elements = soup.find_all(class_=\"col-md-6\") # Find all elements with class \"col-md-6\"\n","\n","    content = \"\" # Create an empty string to store the content\n","\n","    # Iterate over the elements and extract the content inside <pre> tags\n","    for element in col_md_6_elements:\n","        pre_tags = element.find_all(\"pre\")\n","        for pre_tag in pre_tags:\n","            content += pre_tag.get_text() + \"\\n\"\n","\n","    file_name = f\"{i + 1}_{title}.txt\" # Create the file path using the title as the filename\n","    file_path = os.path.join(downloads_folder, file_name)\n","\n","    with open(file_path, \"w\") as file: # Write the content to the file\n","        file.write(content)\n","\n","    print(f\"Saved content of URL {i + 1} to {file_path}\")\n"]}]}